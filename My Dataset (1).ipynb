{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82749b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 956 images belonging to 3 classes.\n",
      "Found 75 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 177s 6s/step - loss: 1.0842 - accuracy: 0.7636 - val_loss: 0.5188 - val_accuracy: 0.8133\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 203s 7s/step - loss: 0.1770 - accuracy: 0.9477 - val_loss: 0.1765 - val_accuracy: 0.8400\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 201s 7s/step - loss: 0.1267 - accuracy: 0.9550 - val_loss: 0.1208 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 203s 7s/step - loss: 0.1125 - accuracy: 0.9613 - val_loss: 0.1376 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 200s 7s/step - loss: 0.0820 - accuracy: 0.9707 - val_loss: 0.0990 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 225s 8s/step - loss: 0.0687 - accuracy: 0.9770 - val_loss: 0.0876 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 221s 7s/step - loss: 0.0641 - accuracy: 0.9728 - val_loss: 0.0807 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 215s 7s/step - loss: 0.0583 - accuracy: 0.9812 - val_loss: 0.0998 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 197s 7s/step - loss: 0.0461 - accuracy: 0.9864 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 204s 7s/step - loss: 0.0586 - accuracy: 0.9812 - val_loss: 0.0633 - val_accuracy: 1.0000\n",
      "2/2 [==============================] - 12s 6s/step - loss: 0.0617 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: laser_line_detection_model_new\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: laser_line_detection_model_new\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Define the folder paths and labels\n",
    "train_folder = r\"C:\\Users\\ADMIN\\Desktop\\DATASETS\\Project Images 1\\train\"\n",
    "test_folder = r\"C:\\Users\\ADMIN\\Desktop\\DATASETS\\Project Images 1\\test\"\n",
    "labels = ['Laser Line Detected - No Obstacle Detected', 'Laser Line Detected - Obstacle Detected', 'Laser Line Not Detected']\n",
    "\n",
    "# Define the batch size and image dimensions\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Load and preprocess the training images and labels\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_folder,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Load and preprocess the test images and labels\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_folder,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Load the VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new layers on top of the base model\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(labels), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model for 10 epochs with batch size of 32\n",
    "epochs = 10\n",
    "history = model.fit(train_generator, epochs=epochs, validation_data=test_generator)\n",
    "\n",
    "# Evaluate the model on the test images\n",
    "loss, accuracy = model.evaluate(test_generator, steps=test_generator.n // test_generator.batch_size)\n",
    "\n",
    "model.save('laser_line_detection_model_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 388ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the folder paths and labels\n",
    "train_folder = r\"C:\\Users\\ADMIN\\Desktop\\DATASETS\\Project Images 1\\train\"\n",
    "labels = ['Laser Line Detected - No Obstacle Detected', 'Laser Line Detected - Obstacle Detected', 'Laser Line Not Detected']\n",
    "\n",
    "# Load the trained model\n",
    "model = keras.models.load_model('laser_line_detection_model_new')\n",
    "\n",
    "# Load and preprocess the user input image\n",
    "#img_path = input(\"Enter the image path: \")\n",
    "img_path = r\"C:\\Users\\ADMIN\\Desktop\\DATASETS\\Project Images 1\\Capture - Copy (3).JPG\"\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = img / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Make a prediction on the user input image\n",
    "predictions = model.predict(img)\n",
    "predicted_class_index = np.argmax(predictions[0])\n",
    "predicted_label = labels[predicted_class_index]\n",
    "\n",
    "# Add the predicted label on top of the user input image\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.putText(img, predicted_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "# Show the image with the predicted label on top\n",
    "cv2.imshow('Predicted Label', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9fc20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
